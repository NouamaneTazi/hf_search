{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyP3dXRfcXLa"
      },
      "source": [
        "# Retrieve & Re-Rank Demo over Simple Wikipedia\n",
        "\n",
        "This examples demonstrates the Retrieve & Re-Rank Setup and allows to search over [Simple Wikipedia](https://simple.wikipedia.org/wiki/Main_Page).\n",
        "\n",
        "You can input a query or a question. The script then uses semantic search\n",
        "to find relevant passages in Simple English Wikipedia (as it is smaller and fits better in RAM).\n",
        "\n",
        "For semantic search, we use `SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')` and retrieve\n",
        "32 potentially passages that answer the input query.\n",
        "\n",
        "Next, we use a more powerful CrossEncoder (`cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')`) that\n",
        "scores the query and all retrieved passages for their relevancy. The cross-encoder further boost the performance,\n",
        "especially when you search over a corpus for which the bi-encoder was not trained for.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X2R9TjVzNV_E"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U sentence-transformers rank_bm25 marko"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/projects/hf_search"
      ],
      "metadata": {
        "id": "tfn87_mLIdkg",
        "outputId": "47cd8c39-be22-4a44-90f1-c2977752cd93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/projects/hf_search\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "passages_df = []\n",
        "from tqdm.notebook import tqdm\n",
        "for i, row in tqdm(df.iterrows()):\n",
        "    text = row[\"readme\"]\n",
        "    if text:\n",
        "        doc = md.parse(text)\n",
        "        passages_df.extend([{\"id\":i,\n",
        "                             \"modelId\":row[\"modelId\"],\n",
        "                             \"passage\":md.render(e) \n",
        "                             } for e in doc.children if e.get_type() not in [\"BlankLine\", \"ThematicBreak\"]])\n",
        "passages_df = pd.DataFrame(passages_df)\n",
        "passages_df.to_json('passages.jsonl', orient='records', lines=True)\n",
        "\n",
        "passages_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455,
          "referenced_widgets": [
            "46d140a2f0bd4a9bbadfa39c8e39c1b6",
            "6dbf48a2f67e42df819dc887b959cd93",
            "fda2ff46db5849069594e944afbb933a",
            "2ec26f35920d4d82a1f746fd4b740993",
            "c81233fc43704751982dacc2b5169a79",
            "f5a096d690924d7397a8ff31449fe2e1",
            "df9deb382753480da8037cf74a038af5",
            "ac20bd02eab54fde88644f0796e21cee",
            "31e05a2606a6472f9f3ca05833b4ec57",
            "d17288d86fe54e45a1cf655e8b7356c0",
            "160a20e68a0a42a5b1824e47a80a1278"
          ]
        },
        "id": "zYUZu_flJwPA",
        "outputId": "cfb6c8e4-1d0a-4b60-cc2b-b337ed1ef078"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46d140a2f0bd4a9bbadfa39c8e39c1b6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-53d8aea8-52bc-4ef4-bf57-4e47b8e9a433\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>modelId</th>\n",
              "      <th>passage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tizaino/bert-base-uncased-finetuned-Pisa</td>\n",
              "      <td>license: apache-2.0\\ntags:\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>tizaino/bert-base-uncased-finetuned-Pisa</td>\n",
              "      <td>- generated_from_trainer\\nmodel-index:\\n- name...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>tizaino/bert-base-uncased-finetuned-Pisa</td>\n",
              "      <td>&lt;!-- This model card has been generated automa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>tizaino/bert-base-uncased-finetuned-Pisa</td>\n",
              "      <td># bert-base-uncased-finetuned-Pisa\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>tizaino/bert-base-uncased-finetuned-Pisa</td>\n",
              "      <td>This model is a fine-tuned version of [bert-ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254360</th>\n",
              "      <td>28912</td>\n",
              "      <td>SongRb/distilbert-base-uncased-finetuned-cola</td>\n",
              "      <td>- learning_rate: 2e-05\\n- train_batch_size: 16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254361</th>\n",
              "      <td>28912</td>\n",
              "      <td>SongRb/distilbert-base-uncased-finetuned-cola</td>\n",
              "      <td>### Training results\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254362</th>\n",
              "      <td>28912</td>\n",
              "      <td>SongRb/distilbert-base-uncased-finetuned-cola</td>\n",
              "      <td>| Training Loss | Epoch | Step | Validation Lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254363</th>\n",
              "      <td>28912</td>\n",
              "      <td>SongRb/distilbert-base-uncased-finetuned-cola</td>\n",
              "      <td>### Framework versions\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254364</th>\n",
              "      <td>28912</td>\n",
              "      <td>SongRb/distilbert-base-uncased-finetuned-cola</td>\n",
              "      <td>- Transformers 4.10.0.dev0\\n- Pytorch 1.8.1\\n-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>254365 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53d8aea8-52bc-4ef4-bf57-4e47b8e9a433')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53d8aea8-52bc-4ef4-bf57-4e47b8e9a433 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53d8aea8-52bc-4ef4-bf57-4e47b8e9a433');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           id  ...                                            passage\n",
              "0           0  ...                       license: apache-2.0\\ntags:\\n\n",
              "1           0  ...  - generated_from_trainer\\nmodel-index:\\n- name...\n",
              "2           0  ...  <!-- This model card has been generated automa...\n",
              "3           0  ...               # bert-base-uncased-finetuned-Pisa\\n\n",
              "4           0  ...  This model is a fine-tuned version of [bert-ba...\n",
              "...       ...  ...                                                ...\n",
              "254360  28912  ...  - learning_rate: 2e-05\\n- train_batch_size: 16...\n",
              "254361  28912  ...                             ### Training results\\n\n",
              "254362  28912  ...  | Training Loss | Epoch | Step | Validation Lo...\n",
              "254363  28912  ...                           ### Framework versions\\n\n",
              "254364  28912  ...  - Transformers 4.10.0.dev0\\n- Pytorch 1.8.1\\n-...\n",
              "\n",
              "[254365 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "passages_df.to_json('passages.jsonl', orient='records', lines=True)"
      ],
      "metadata": {
        "id": "VzwRteTMdPRH"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_hDi8KzNgMM",
        "outputId": "531e5f8f-f2eb-4efc-8a83-e8517dd98a96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passages: 254365\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import json\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "import gzip\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from marko import Markdown\n",
        "md = Markdown()\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"Warning: No GPU found. Please add GPU to your notebook\")\n",
        "\n",
        "\n",
        "#We use the Bi-Encoder to encode all passages, so that we can use it with sematic search\n",
        "bi_encoder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
        "bi_encoder.max_seq_length = 256     #Truncate long passages to 256 tokens\n",
        "top_k = 32                          #Number of passages we want to retrieve with the bi-encoder\n",
        "\n",
        "#The bi-encoder will retrieve 100 documents. We use a cross-encoder, to re-rank the results list to improve the quality\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "# As dataset, we use Simple English Wikipedia. Compared to the full English wikipedia, it has only\n",
        "# about 170k articles. We split these articles into paragraphs and encode them with the bi-encoder\n",
        "\n",
        "passages_df = pd.read_json('passages.jsonl', lines=True)\n",
        "passages = passages_df[\"passage\"].values.tolist()\n",
        "\n",
        "print(\"Passages:\", len(passages))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We encode all passages into our vector space. This takes about 5 minutes (depends on your GPU speed)\n",
        "corpus_embeddings = bi_encoder.encode(passages, convert_to_tensor=True, show_progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cd000d01e3944d9d80dbcbafe5ab9065",
            "f3e5d815d8a44e0eaae7ca1a862f2fd3",
            "f67583b3baf24c55b96d8994a717ebb5",
            "19fefe9b3bb745b9b1535114f73c7b4c",
            "94841d876cbf43bebaeeb4feb573aa69",
            "ec3de298a3a84e938396688fee95e9cf",
            "36d06eb94b8146afb5156f416c32573c",
            "157d3639f9f84ecb8173181380dcb377",
            "08830f54c5bb45e1ad9eb7efcea90149",
            "565ca6fb7fce496bb9a03f0dcfa92539",
            "c3a7dcb140b84cb5818ee0a974fb3efc"
          ]
        },
        "id": "HhCugMzlJ1MJ",
        "outputId": "aad1e0cb-6d01-4116-dcc5-761fe27aedc9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd000d01e3944d9d80dbcbafe5ab9065",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Batches:   0%|          | 0/7949 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(corpus_embeddings, 'corpus_embeddings.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCT0W_LjfXBf",
        "outputId": "a45a5d5c-5f6d-47e1-a548-f119b529f981"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['corpus_embeddings.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "dd8523327ccf480ba23dcfb8a313bdb7",
            "8849cd6bc6ec43e2b96adb704713e186",
            "9873b571f9ee4fa3a345e49f16f157f7",
            "49aa891525f3437c80045769040143f1",
            "5acb63e7b6ae41a995dea8a160ad9bba",
            "2f3b737b2914400fb78997bf6ccd556d",
            "04a78982ef99408cb7dae8d05d1004f1",
            "54c3966fb16b4edeb8466a9d495fdfd2",
            "05b2531b28684838acbd1d04b68335c6",
            "fdcdcda969b543cab79983a3c36060cd",
            "c7fc9cf57c7845fa8263b1642c614225"
          ]
        },
        "id": "0rueR6ovrs01",
        "outputId": "3c20495b-d0d2-458f-9b12-713233276724"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd8523327ccf480ba23dcfb8a313bdb7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/254365 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# We also compare the results to lexical search (keyword search). Here, we use \n",
        "# the BM25 algorithm which is implemented in the rank_bm25 package.\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sklearn.feature_extraction import _stop_words\n",
        "import string\n",
        "from tqdm.autonotebook import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# We lower case our text and remove stop-words from indexing\n",
        "def bm25_tokenizer(text):\n",
        "    tokenized_doc = []\n",
        "    for token in text.lower().split():\n",
        "        token = token.strip(string.punctuation)\n",
        "\n",
        "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
        "            tokenized_doc.append(token)\n",
        "    return tokenized_doc\n",
        "\n",
        "\n",
        "tokenized_corpus = []\n",
        "for passage in tqdm(passages):\n",
        "    tokenized_corpus.append(bm25_tokenizer(passage))\n",
        "\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "UlArb7kqN3Re"
      },
      "outputs": [],
      "source": [
        "# This function will search all wikipedia articles for passages that\n",
        "# answer the query\n",
        "def search(query):\n",
        "    print(\"Input question:\", query)\n",
        "\n",
        "    ##### BM25 search (lexical search) #####\n",
        "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
        "    top_n = np.argpartition(bm25_scores, -5)[-5:]\n",
        "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
        "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
        "    \n",
        "    print(\"Top-3 lexical search (BM25) hits\")\n",
        "    for hit in bm25_hits[0:3]:\n",
        "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], passages[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
        "\n",
        "    ##### Sematic Search #####\n",
        "    # Encode the query using the bi-encoder and find potentially relevant passages\n",
        "    question_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
        "    question_embedding = question_embedding.cuda()\n",
        "    hits = util.semantic_search(question_embedding, corpus_embeddings, top_k=top_k)\n",
        "    hits = hits[0]  # Get the hits for the first query\n",
        "\n",
        "    ##### Re-Ranking #####\n",
        "    # Now, score all retrieved passages with the cross_encoder\n",
        "    cross_inp = [[query, passages[hit['corpus_id']]] for hit in hits]\n",
        "    cross_scores = cross_encoder.predict(cross_inp)\n",
        "\n",
        "    # Sort results by the cross-encoder scores\n",
        "    for idx in range(len(cross_scores)):\n",
        "        hits[idx]['cross-score'] = cross_scores[idx]\n",
        "\n",
        "    # Output of top-5 hits from bi-encoder\n",
        "    print(\"\\n-------------------------\\n\")\n",
        "    print(\"Top-3 Bi-Encoder Retrieval hits\")\n",
        "    hits = sorted(hits, key=lambda x: x['score'], reverse=True)\n",
        "    for hit in hits[0:3]:\n",
        "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], passages[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
        "\n",
        "    # Output of top-5 hits from re-ranker\n",
        "    print(\"\\n-------------------------\\n\")\n",
        "    print(\"Top-3 Cross-Encoder Re-ranker hits\")\n",
        "    hits = sorted(hits, key=lambda x: x['cross-score'], reverse=True)\n",
        "    for hit in hits[0:3]:\n",
        "        print(\"\\t{:.3f}\\t{}\".format(hit['cross-score'], passages[hit['corpus_id']].replace(\"\\n\", \" \")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J0Zxgw0artg",
        "outputId": "22b766a5-4f9d-469b-828a-cbc35b234312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input question: translate arabic to french\n",
            "Top-3 lexical search (BM25) hits\n",
            "\t14.908\tHere is how to use this model to translate legal text from Deustch to French in PyTorch: \n",
            "\t14.908\tHere is how to use this model to translate legal text from French to Deustch in PyTorch: \n",
            "\t14.908\tHere is how to use this model to translate legal text from Cszech to French in PyTorch: \n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top-3 Bi-Encoder Retrieval hits\n",
            "\t0.775\tlanguage: \"Arabic\" \n",
            "\t0.658\t# Arabic QA \n",
            "\t0.630\t# arabic-iti \n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top-3 Cross-Encoder Re-ranker hits\n",
            "\t3.077\tThis is a model for translating English to Arabic. The special about this model that is take into considration the using of additional Arabic characters like `پ` or `گ`. \n",
            "\t-2.486\tlanguage: \"Arabic\" \n",
            "\t-3.603\t# An English-Arabic Bilingual Encoder \n"
          ]
        }
      ],
      "source": [
        "search(query = \"translate arabic to french\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WawjqQBJa3FP",
        "outputId": "9e6a836c-7791-4813-ed45-8d6687561675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input question: sentence pair classification\n",
            "Top-3 lexical search (BM25) hits\n",
            "\t15.199\tCCaligned (en-id sentence pair) \n",
            "\t14.940\tThis model can be used using Huggingface Transformers. I have created a pipeline for a sentence pair classification. Hope it will be useful. \n",
            "\t14.381\t### Finetuned on annual report sentence pair \n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top-3 Bi-Encoder Retrieval hits\n",
            "\t0.730\t**Multi-class sentence classification:** \n",
            "\t0.669\tThe model will predict scores for the pairs `('Sentence 1', 'Sentence 2')` and `('Sentence 3', 'Sentence 4')`. \n",
            "\t0.669\tThe model will predict scores for the pairs `('Sentence 1', 'Sentence 2')` and `('Sentence 3', 'Sentence 4')`. \n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top-3 Cross-Encoder Re-ranker hits\n",
            "\t5.674\tThis model can be used using Huggingface Transformers. I have created a pipeline for a sentence pair classification. Hope it will be useful. \n",
            "\t1.662\t**Multi-class sentence classification:** \n",
            "\t0.285\tThe model will predict scores for the pairs `('Sentence 1', 'Sentence 2')` and `('Sentence 3', 'Sentence 4')`. \n"
          ]
        }
      ],
      "source": [
        "search(query = \"sentence pair classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "soZ1nH4_I4Zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d97e9b-75cc-4a5e-a6b5-5d694671abb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input question: audio preprocessing\n",
            "Top-3 lexical search (BM25) hits\n",
            "\t9.432\t# Audio to Audio repository template \n",
            "\t9.432\t# Audio to Audio repository template \n",
            "\t9.024\t### Preprocessing \n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top-3 Bi-Encoder Retrieval hits\n",
            "\t0.638\t# Audio-to-Audio Test \n",
            "\t0.611\tUpdate the audio_path as per your local file structure. \n",
            "\t0.609\t- asteroid - audio - ConvTasNet - audio-to-audio datasets: - wham - sep_clean license: cc-by-sa-4.0 widget: - example_title: Librispeech sample 1 src: https://cdn-media.huggingface.co/speech_samples/sample1.flac \n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top-3 Cross-Encoder Re-ranker hits\n",
            "\t-1.592\t```python import torch import torchaudio import librosa from datasets import load_dataset, load_metric from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor import re  # test_data = #TODO: WRITE YOUR CODE TO LOAD THE TEST DATASET. For sample see the Colab link in Training Section.  wer = load_metric(\"wer\") processor = Wav2Vec2Processor.from_pretrained(\"gchhablani/wav2vec2-large-xlsr-mr-3\") model = Wav2Vec2ForCTC.from_pretrained(\"gchhablani/wav2vec2-large-xlsr-mr-3\") model.to(\"cuda\")  chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\–\\…]'   # Preprocessing the datasets. # We need to read the audio files as arrays def speech_file_to_array_fn(batch):     batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower()     speech_array, sampling_rate = torchaudio.load(batch[\"audio_path\"])     batch[\"speech\"] = librosa.resample(speech_array[0].numpy(), sampling_rate, 16_000)     return batch  test_data= test_data.map(speech_file_to_array_fn)  # Preprocessing the datasets. # We need to read the audio files as arrays def evaluate(batch):     inputs = processor(batch[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)     with torch.no_grad():         logits = model(inputs.input_values.to(\"cuda\"), attention_mask=inputs.attention_mask.to(\"cuda\")).logits         pred_ids = torch.argmax(logits, dim=-1)         batch[\"pred_strings\"] = processor.batch_decode(pred_ids)         return batch  result = test_data.map(evaluate, batched=True, batch_size=8) print(\"WER: {:2f}\".format(100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"text\"]))) ``` \n",
            "\t-2.044\t```python import torch import torchaudio from datasets import load_dataset, load_metric from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor import re  test_dataset = load_dataset(\"common_voice\", \"tr\", split=\"test\") wer = load_metric(\"wer\")  processor = Wav2Vec2Processor.from_pretrained(\"ceyda/wav2vec2-base-960-turkish\") model = Wav2Vec2ForCTC.from_pretrained(\"ceyda/wav2vec2-base-960-turkish\") model.to(\"cuda\")  chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\‘\\”\\'\\`…\\’»«]' resampler = torchaudio.transforms.Resample(48_000, 16_000)  # Preprocessing the datasets. # We need to read the audio files as arrays def speech_file_to_array_fn(batch):     batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower()     speech_array, sampling_rate = torchaudio.load(batch[\"path\"])     batch[\"speech\"] = resampler(speech_array).squeeze().numpy()     return batch  test_dataset = test_dataset.map(speech_file_to_array_fn)  # Preprocessing the datasets. # We need to read the aduio files as arrays  #Attention mask is not used because the base-model was not trained with it. reference: https://github.com/huggingface/transformers/blob/403d530eec105c0e229fc2b754afdf77a4439def/src/transformers/models/wav2vec2/tokenization_wav2vec2.py#L305 def evaluate(batch):     inputs = processor(batch[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)      with torch.no_grad():         logits = model(inputs.input_values.to(\"cuda\")).logits      pred_ids = torch.argmax(logits, dim=-1)     batch[\"pred_strings\"] = processor.batch_decode(pred_ids,skip_special_tokens=True)     return batch  result = test_dataset.map(evaluate, batched=True, batch_size=8)  print(\"WER: {:2f}\".format(100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"]))) ``` \n",
            "\t-2.904\t```python import torch import torchaudio from datasets import load_dataset from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor  test_dataset = load_dataset(\"common_voice\", \"ca\", split=\"test[:2%]\")  processor = Wav2Vec2Processor.from_pretrained(\"ccoreilly/wav2vec2-large-xlsr-catala\")  model = Wav2Vec2ForCTC.from_pretrained(\"ccoreilly/wav2vec2-large-xlsr-catala\")  resampler = torchaudio.transforms.Resample(48_000, 16_000)  # Preprocessing the datasets. # We need to read the audio files as arrays def speech_file_to_array_fn(batch): \tspeech_array, sampling_rate = torchaudio.load(batch[\"path\"]) \tbatch[\"speech\"] = resampler(speech_array).squeeze().numpy() \treturn batch  test_dataset = test_dataset.map(speech_file_to_array_fn) inputs = processor(test_dataset[\"speech\"][:2], sampling_rate=16_000, return_tensors=\"pt\", padding=True)  with torch.no_grad(): \tlogits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits  predicted_ids = torch.argmax(logits, dim=-1)  print(\"Prediction:\", processor.batch_decode(predicted_ids)) print(\"Reference:\", test_dataset[\"sentence\"][:2]) ``` \n"
          ]
        }
      ],
      "source": [
        "search(query = \"audio preprocessing\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search(query = \"audio to text model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDSGxDnGghzY",
        "outputId": "7643a53f-b8ab-4545-96e7-2de2971149bf"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input question: audio to text model\n",
            "Top-3 lexical search (BM25) hits\n",
            "\t9.432\t# Audio to Audio repository template \n",
            "\t9.432\t# Audio to Audio repository template \n",
            "\t8.503\tYou can use the model via the Audio Classification pipeline: \n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top-3 Bi-Encoder Retrieval hits\n",
            "\t0.715\tYou can use the model via the Audio Classification pipeline: \n",
            "\t0.715\tYou can use the model via the Audio Classification pipeline: \n",
            "\t0.715\tYou can use the model via the Audio Classification pipeline: \n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top-3 Cross-Encoder Re-ranker hits\n",
            "\t3.205\t# Text to Speech Model \n",
            "\t2.942\t# Personal speech to text model \n",
            "\t0.871\tTo transcribe audio files the model can be used as a standalone acoustic model as follows: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search(query = \"image to text model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BERn33UJg_8G",
        "outputId": "4bc2dd56-c0dd-43db-bc82-794e62e61fda"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input question: image to text model\n",
            "Top-3 lexical search (BM25) hits\n",
            "\t12.540\tYou can use the model for image and text retrieval. \n",
            "\t12.540\tYou can use the model for image and text retrieval. \n",
            "\t11.632\t# Text To Image repository template \n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top-3 Bi-Encoder Retrieval hits\n",
            "\t0.735\tYou can use the model for image and text retrieval. \n",
            "\t0.735\tYou can use the model for image and text retrieval. \n",
            "\t0.659\t## Generate images from text \n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top-3 Cross-Encoder Re-ranker hits\n",
            "\t7.029\tCheck out the model text-to-image and image-to-image capabilities using [this demo](https://huggingface.co/spaces/sujitpal/clip-rsicd-demo). \n",
            "\t7.029\tCheck out the model text-to-image and image-to-image capabilities using [this demo](https://huggingface.co/spaces/sujitpal/clip-rsicd-demo). \n",
            "\t5.815\tYou can use the model for image and text retrieval. \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "retrieve_rerank_simple_wikipedia.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46d140a2f0bd4a9bbadfa39c8e39c1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6dbf48a2f67e42df819dc887b959cd93",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fda2ff46db5849069594e944afbb933a",
              "IPY_MODEL_2ec26f35920d4d82a1f746fd4b740993",
              "IPY_MODEL_c81233fc43704751982dacc2b5169a79"
            ]
          }
        },
        "6dbf48a2f67e42df819dc887b959cd93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fda2ff46db5849069594e944afbb933a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f5a096d690924d7397a8ff31449fe2e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df9deb382753480da8037cf74a038af5"
          }
        },
        "2ec26f35920d4d82a1f746fd4b740993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ac20bd02eab54fde88644f0796e21cee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_31e05a2606a6472f9f3ca05833b4ec57"
          }
        },
        "c81233fc43704751982dacc2b5169a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d17288d86fe54e45a1cf655e8b7356c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28914/? [03:24&lt;00:00, 99.92it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_160a20e68a0a42a5b1824e47a80a1278"
          }
        },
        "f5a096d690924d7397a8ff31449fe2e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df9deb382753480da8037cf74a038af5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac20bd02eab54fde88644f0796e21cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "31e05a2606a6472f9f3ca05833b4ec57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d17288d86fe54e45a1cf655e8b7356c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "160a20e68a0a42a5b1824e47a80a1278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd000d01e3944d9d80dbcbafe5ab9065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3e5d815d8a44e0eaae7ca1a862f2fd3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f67583b3baf24c55b96d8994a717ebb5",
              "IPY_MODEL_19fefe9b3bb745b9b1535114f73c7b4c",
              "IPY_MODEL_94841d876cbf43bebaeeb4feb573aa69"
            ]
          }
        },
        "f3e5d815d8a44e0eaae7ca1a862f2fd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f67583b3baf24c55b96d8994a717ebb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ec3de298a3a84e938396688fee95e9cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Batches: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36d06eb94b8146afb5156f416c32573c"
          }
        },
        "19fefe9b3bb745b9b1535114f73c7b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_157d3639f9f84ecb8173181380dcb377",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7949,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7949,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08830f54c5bb45e1ad9eb7efcea90149"
          }
        },
        "94841d876cbf43bebaeeb4feb573aa69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_565ca6fb7fce496bb9a03f0dcfa92539",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7949/7949 [08:02&lt;00:00, 110.76it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3a7dcb140b84cb5818ee0a974fb3efc"
          }
        },
        "ec3de298a3a84e938396688fee95e9cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36d06eb94b8146afb5156f416c32573c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "157d3639f9f84ecb8173181380dcb377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08830f54c5bb45e1ad9eb7efcea90149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "565ca6fb7fce496bb9a03f0dcfa92539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3a7dcb140b84cb5818ee0a974fb3efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd8523327ccf480ba23dcfb8a313bdb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8849cd6bc6ec43e2b96adb704713e186",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9873b571f9ee4fa3a345e49f16f157f7",
              "IPY_MODEL_49aa891525f3437c80045769040143f1",
              "IPY_MODEL_5acb63e7b6ae41a995dea8a160ad9bba"
            ]
          }
        },
        "8849cd6bc6ec43e2b96adb704713e186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9873b571f9ee4fa3a345e49f16f157f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f3b737b2914400fb78997bf6ccd556d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04a78982ef99408cb7dae8d05d1004f1"
          }
        },
        "49aa891525f3437c80045769040143f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_54c3966fb16b4edeb8466a9d495fdfd2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 254365,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 254365,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05b2531b28684838acbd1d04b68335c6"
          }
        },
        "5acb63e7b6ae41a995dea8a160ad9bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fdcdcda969b543cab79983a3c36060cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 254365/254365 [00:05&lt;00:00, 66580.46it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7fc9cf57c7845fa8263b1642c614225"
          }
        },
        "2f3b737b2914400fb78997bf6ccd556d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04a78982ef99408cb7dae8d05d1004f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54c3966fb16b4edeb8466a9d495fdfd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05b2531b28684838acbd1d04b68335c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fdcdcda969b543cab79983a3c36060cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7fc9cf57c7845fa8263b1642c614225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}